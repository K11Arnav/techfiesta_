# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Cb7jbzXjwbvswNLrqXa_DXGSg4HJcxWf
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, f1_score, roc_auc_score
from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, recall_score
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from sklearn.ensemble import IsolationForest
from sklearn.ensemble import IsolationForest

import kagglehub
# Download dataset from Kaggle Hub
print("üì• Downloading dataset from Kaggle Hub...")
path = kagglehub.dataset_download("mlg-ulb/creditcardfraud")
print(f"‚úÖ Dataset downloaded to: {path}")

# Display available CSVs
import os
csv_files = [f for f in os.listdir(path) if f.endswith('.csv')]
print(f"üìÅ Available CSV files: {csv_files}")

# Load dataset by specifying the CSV filename manually
df = pd.read_csv(os.path.join(path, "creditcard.csv"))   # <--- PUT YOUR CSV NAME HERE
print(f"‚úÖ Dataset loaded successfully!")
print(f"üìä Shape: {df.shape}")
df.head()

# 2) CHECK MISSING VALUES
# ================================
print("\nMissing Values:\n", df.isnull().sum())



from sklearn.model_selection import train_test_split, cross_val_predict
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import (
    classification_report,
    f1_score,
    roc_auc_score,
    average_precision_score,
    precision_recall_curve
)
from xgboost import XGBClassifier
import numpy as np

# ... [Splitting and Scaling code remains the same] ...
# Split
X = df.drop('Class', axis=1)
y = df['Class']

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Initialize scaler
scaler = StandardScaler()

# Create copies and scale properly
X_train_scaled = X_train.copy()
X_test_scaled = X_test.copy()

X_train_scaled[['Amount', 'Time']] = scaler.fit_transform(X_train[['Amount', 'Time']])
X_test_scaled[['Amount', 'Time']] = scaler.transform(X_test[['Amount', 'Time']])

# Correct imbalance handling
fraud_ratio = (y_train == 0).sum() / (y_train == 1).sum()

model = XGBClassifier(
    max_depth=6,
    n_estimators=400,
    learning_rate=0.05,
    subsample=0.8,
    colsample_bytree=0.8,
    scale_pos_weight=fraud_ratio,
    eval_metric='aucpr',
    tree_method='hist',
    random_state=42,
    n_jobs=-1
)

model.fit(X_train_scaled, y_train)

# --- FIX 1: Threshold Tuning on TRAINING Data (via CV) ---
# We get out-of-fold predictions to tune the threshold without touching the Test set
y_train_prob_cv = cross_val_predict(
    model,
    X_train_scaled,
    y_train,
    cv=3,
    method='predict_proba',
    n_jobs=-1
)[:, 1]

# --- FIX 2: Correct Array Indexing ---
precision, recall, thresholds = precision_recall_curve(y_train, y_train_prob_cv)

# Remove the last element of precision/recall to match thresholds length
f1_scores = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1] + 1e-8)
best_threshold = thresholds[np.argmax(f1_scores)]

print(f"Optimal Threshold (tuned on Train): {best_threshold:.4f}")

# --- Final Evaluation on Test Set ---
# Now we apply the threshold derived from Train to the Test set
y_test_prob = model.predict_proba(X_test_scaled)[:, 1]
y_test_pred = (y_test_prob >= best_threshold).astype(int)

print("\nClassification Report (Test Data):")
print(classification_report(y_test, y_test_pred))
print("PR-AUC:", average_precision_score(y_test, y_test_prob))